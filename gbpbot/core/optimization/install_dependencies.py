#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Installation des d√©pendances pour l'optimisation mat√©rielle
=========================================================

Ce script installe les biblioth√®ques Python n√©cessaires pour
le module d'optimisation mat√©rielle du GBPBot, notamment les
biblioth√®ques pour la d√©tection du mat√©riel et l'optimisation
des performances.
"""

import os
import sys
import subprocess
import platform
import logging
from typing import List, Dict, Any, Tuple

# Configuration du logger
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("install_optimization_deps")

# D√©pendances requises pour l'optimisation mat√©rielle
REQUIRED_PACKAGES = [
    "psutil>=5.9.0",       # Surveillance syst√®me
    "humanize>=4.0.0",     # Formatage convivial des chiffres
]

# D√©pendances optionnelles par plateforme
PLATFORM_PACKAGES = {
    "win32": [
        "pywin32>=300",     # Acc√®s aux API Windows
        "wmi>=1.5.1",       # Acc√®s WMI pour la d√©tection mat√©rielle
    ],
    "linux": [
        "py-cpuinfo>=8.0.0",  # Informations CPU d√©taill√©es
    ],
    "darwin": [
        "py-cpuinfo>=8.0.0",  # Informations CPU d√©taill√©es
    ]
}

# D√©pendances pour l'optimisation GPU par type
GPU_PACKAGES = {
    "tensorflow": [
        "tensorflow>=2.9.0;platform_system!='Darwin' or platform_machine!='arm64'",  # TensorFlow pour GPU
        "tensorflow-macos>=2.9.0;platform_system=='Darwin' and platform_machine=='arm64'",  # TensorFlow pour Mac M1
    ],
    "torch": [
        "torch>=1.11.0",    # PyTorch
        "torchvision>=0.12.0",  # Modules de vision pour PyTorch
    ],
    "common": [
        "numpy>=1.22.0",    # Calcul num√©rique
    ]
}

def print_banner():
    """Affiche la banni√®re d'installation"""
    banner = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                            ‚ïë
‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó      ‚ïë
‚ïë  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù      ‚ïë
‚ïë  ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë         ‚ïë
‚ïë  ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë         ‚ïë
‚ïë  ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù   ‚ñà‚ñà‚ïë         ‚ïë
‚ïë   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù    ‚ïö‚ïê‚ïù         ‚ïë
‚ïë                                                            ‚ïë
‚ïë        Installation des D√©pendances d'Optimisation         ‚ïë
‚ïë                                                            ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """
    print(banner)

def get_gpu_info() -> Dict[str, Any]:
    """
    D√©tecte la pr√©sence d'un GPU NVIDIA ou AMD et retourne les informations.
    
    Returns:
        Dict contenant les informations GPU d√©tect√©es
    """
    gpu_info = {
        "nvidia_available": False,
        "amd_available": False,
        "intel_available": False,
        "apple_silicon": False,
        "model": None
    }
    
    # D√©tection Apple Silicon
    if platform.system() == "Darwin" and platform.machine() == "arm64":
        gpu_info["apple_silicon"] = True
        gpu_info["model"] = "Apple Silicon"
        return gpu_info
    
    try:
        if platform.system() == "Windows":
            # Utiliser WMI pour d√©tecter les GPU sur Windows
            try:
                import wmi
                w = wmi.WMI()
                for gpu in w.Win32_VideoController():
                    if "NVIDIA" in gpu.Name:
                        gpu_info["nvidia_available"] = True
                        gpu_info["model"] = gpu.Name
                        break
                    elif "AMD" in gpu.Name or "Radeon" in gpu.Name:
                        gpu_info["amd_available"] = True
                        gpu_info["model"] = gpu.Name
                        break
                    elif "Intel" in gpu.Name:
                        gpu_info["intel_available"] = True
                        gpu_info["model"] = gpu.Name
            except ImportError:
                logger.warning("WMI non disponible, impossible de d√©tecter le GPU")
        
        elif platform.system() == "Linux":
            # V√©rifier la pr√©sence de NVIDIA via lspci
            try:
                output = subprocess.check_output(["lspci"], text=True)
                if "NVIDIA" in output:
                    gpu_info["nvidia_available"] = True
                    # Essayer d'extraire le nom du mod√®le
                    for line in output.split("\n"):
                        if "NVIDIA" in line:
                            gpu_info["model"] = line.split(":")[-1].strip()
                            break
                elif "AMD" in output or "Radeon" in output:
                    gpu_info["amd_available"] = True
                    # Essayer d'extraire le nom du mod√®le
                    for line in output.split("\n"):
                        if "AMD" in line or "Radeon" in line:
                            gpu_info["model"] = line.split(":")[-1].strip()
                            break
                elif "Intel" in output and "Graphics" in output:
                    gpu_info["intel_available"] = True
                    # Essayer d'extraire le nom du mod√®le
                    for line in output.split("\n"):
                        if "Intel" in line and "Graphics" in line:
                            gpu_info["model"] = line.split(":")[-1].strip()
                            break
            except (subprocess.SubprocessError, FileNotFoundError):
                logger.warning("lspci non disponible, impossible de d√©tecter le GPU")
    
    except Exception as e:
        logger.warning(f"Erreur lors de la d√©tection du GPU: {str(e)}")
    
    return gpu_info

def get_all_packages() -> List[str]:
    """
    D√©termine toutes les d√©pendances √† installer en fonction du mat√©riel d√©tect√©.
    
    Returns:
        Liste des packages √† installer
    """
    packages = REQUIRED_PACKAGES.copy()
    
    # Ajouter les packages sp√©cifiques √† la plateforme
    system = platform.system().lower()
    if system == "windows":
        packages.extend(PLATFORM_PACKAGES["win32"])
    elif system == "linux":
        packages.extend(PLATFORM_PACKAGES["linux"])
    elif system == "darwin":
        packages.extend(PLATFORM_PACKAGES["darwin"])
    
    # D√©tecter le GPU et ajouter les packages correspondants
    gpu_info = get_gpu_info()
    if gpu_info["nvidia_available"]:
        # NVIDIA est d√©tect√©, ajouter PyTorch avec CUDA
        logger.info(f"GPU NVIDIA d√©tect√©: {gpu_info['model']}")
        packages.extend(GPU_PACKAGES["torch"])
        packages.extend(GPU_PACKAGES["tensorflow"])
    elif gpu_info["amd_available"] or gpu_info["intel_available"] or gpu_info["apple_silicon"]:
        # AMD/Intel/Apple Silicon d√©tect√©, ajouter PyTorch sans CUDA
        logger.info(f"GPU d√©tect√©: {gpu_info['model']}")
        packages.extend(GPU_PACKAGES["torch"])
        packages.extend(GPU_PACKAGES["tensorflow"])
    
    # Dans tous les cas, ajouter les packages GPU communs
    packages.extend(GPU_PACKAGES["common"])
    
    return packages

def install_packages(packages: List[str]) -> bool:
    """
    Installe les packages sp√©cifi√©s avec pip.
    
    Args:
        packages: Liste des packages √† installer
        
    Returns:
        True si l'installation a r√©ussi, False sinon
    """
    if not packages:
        logger.info("Aucun package √† installer")
        return True
    
    logger.info(f"Installation de {len(packages)} packages...")
    
    try:
        # Construire la commande pip avec tous les packages
        cmd = [sys.executable, "-m", "pip", "install", "--upgrade"]
        cmd.extend(packages)
        
        # Ex√©cuter l'installation
        logger.info(f"Ex√©cution de la commande: {' '.join(cmd)}")
        subprocess.check_call(cmd)
        
        logger.info("Installation des packages termin√©e avec succ√®s")
        return True
    
    except subprocess.CalledProcessError as e:
        logger.error(f"Erreur lors de l'installation des packages: {str(e)}")
        return False

def check_cuda_availability() -> Tuple[bool, str]:
    """
    V√©rifie si CUDA est disponible et retourne sa version.
    
    Returns:
        Tuple (disponibilit√©, version)
    """
    try:
        import torch
        
        cuda_available = torch.cuda.is_available()
        cuda_version = torch.version.cuda if cuda_available else "Non disponible"
        
        return cuda_available, cuda_version
    
    except ImportError:
        return False, "PyTorch non install√©"

def main():
    """Fonction principale d'installation des d√©pendances"""
    print_banner()
    
    print("\nüìã V√©rification du syst√®me...")
    system = platform.system()
    release = platform.release()
    machine = platform.machine()
    
    print(f"Syst√®me d√©tect√©: {system} {release} ({machine})")
    
    # Obtenir la liste compl√®te des packages √† installer
    packages = get_all_packages()
    
    print(f"\nüì¶ Packages √† installer ({len(packages)}):")
    for package in packages:
        print(f"  - {package}")
    
    # Demander confirmation √† l'utilisateur
    confirm = input("\nüîÑ Continuer avec l'installation? (o/n): ")
    if confirm.lower() != "o":
        print("‚ùå Installation annul√©e")
        return 1
    
    # Installer les packages
    print("\nüîÑ Installation des packages...")
    success = install_packages(packages)
    
    if success:
        print("\n‚úÖ Installation termin√©e avec succ√®s!")
        
        # V√©rifier la disponibilit√© de CUDA si un GPU NVIDIA est d√©tect√©
        gpu_info = get_gpu_info()
        if gpu_info["nvidia_available"]:
            cuda_available, cuda_version = check_cuda_availability()
            
            if cuda_available:
                print(f"\nüéÆ CUDA est disponible (version {cuda_version})!")
                print("  ‚Üí Optimisations GPU activ√©es pour les mod√®les d'IA.")
            else:
                print("\n‚ö†Ô∏è CUDA n'est pas disponible malgr√© la d√©tection d'un GPU NVIDIA.")
                print("  ‚Üí Les performances GPU pourraient √™tre limit√©es.")
        
        print("\nüìù Pour utiliser l'optimiseur mat√©riel, ex√©cutez:")
        print("  python -m gbpbot.core.optimization.optimize_hardware")
        return 0
    else:
        print("\n‚ùå L'installation a √©chou√©. Consultez les messages d'erreur ci-dessus.")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 