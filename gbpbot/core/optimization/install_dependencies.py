#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Installation des dÃ©pendances pour l'optimisation matÃ©rielle
=========================================================

Ce script installe les bibliothÃ¨ques Python nÃ©cessaires pour
le module d'optimisation matÃ©rielle du GBPBot, notamment les
bibliothÃ¨ques pour la dÃ©tection du matÃ©riel et l'optimisation
des performances.
"""

import os
import sys
import subprocess
import platform
import logging
from typing import List, Dict, Any, Tuple

# Configuration du logger
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("install_optimization_deps")

# DÃ©pendances requises pour l'optimisation matÃ©rielle
REQUIRED_PACKAGES = [
    "psutil>=5.9.0",       # Surveillance systÃ¨me
    "humanize>=4.0.0",     # Formatage convivial des chiffres
]

# DÃ©pendances optionnelles par plateforme
PLATFORM_PACKAGES = {
    "win32": [
        "pywin32>=300",     # AccÃ¨s aux API Windows
        "wmi>=1.5.1",       # AccÃ¨s WMI pour la dÃ©tection matÃ©rielle
    ],
    "linux": [
        "py-cpuinfo>=8.0.0",  # Informations CPU dÃ©taillÃ©es
    ],
    "darwin": [
        "py-cpuinfo>=8.0.0",  # Informations CPU dÃ©taillÃ©es
    ]
}

# DÃ©pendances pour l'optimisation GPU par type
GPU_PACKAGES = {
    "tensorflow": [
        "tensorflow>=2.9.0;platform_system!='Darwin' or platform_machine!='arm64'",  # TensorFlow pour GPU
        "tensorflow-macos>=2.9.0;platform_system=='Darwin' and platform_machine=='arm64'",  # TensorFlow pour Mac M1
    ],
    "torch": [
        "torch>=1.11.0",    # PyTorch
        "torchvision>=0.12.0",  # Modules de vision pour PyTorch
    ],
    "common": [
        "numpy>=1.22.0",    # Calcul numÃ©rique
    ]
}

def print_banner():
    """Affiche la banniÃ¨re d'installation"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                            â•‘
â•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—      â•‘
â•‘  â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â•šâ•â•â–ˆâ–ˆâ•”â•â•â•      â•‘
â•‘  â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘         â•‘
â•‘  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘         â•‘
â•‘  â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•   â–ˆâ–ˆâ•‘         â•‘
â•‘   â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•     â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â•â•    â•šâ•â•         â•‘
â•‘                                                            â•‘
â•‘        Installation des DÃ©pendances d'Optimisation         â•‘
â•‘                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)

def get_gpu_info() -> Dict[str, Any]:
    """
    DÃ©tecte la prÃ©sence d'un GPU NVIDIA ou AMD et retourne les informations.
    
    Returns:
        Dict contenant les informations GPU dÃ©tectÃ©es
    """
    gpu_info = {
        "nvidia_available": False,
        "amd_available": False,
        "intel_available": False,
        "apple_silicon": False,
        "model": None
    }
    
    # DÃ©tection Apple Silicon
    if platform.system() == "Darwin" and platform.machine() == "arm64":
        gpu_info["apple_silicon"] = True
        gpu_info["model"] = "Apple Silicon"
        return gpu_info
    
    try:
        if platform.system() == "Windows":
            # Utiliser WMI pour dÃ©tecter les GPU sur Windows
            try:
                import wmi
                w = wmi.WMI()
                for gpu in w.Win32_VideoController():
                    if "NVIDIA" in gpu.Name:
                        gpu_info["nvidia_available"] = True
                        gpu_info["model"] = gpu.Name
                        break
                    elif "AMD" in gpu.Name or "Radeon" in gpu.Name:
                        gpu_info["amd_available"] = True
                        gpu_info["model"] = gpu.Name
                        break
                    elif "Intel" in gpu.Name:
                        gpu_info["intel_available"] = True
                        gpu_info["model"] = gpu.Name
            except ImportError:
                logger.warning("WMI non disponible, impossible de dÃ©tecter le GPU")
        
        elif platform.system() == "Linux":
            # VÃ©rifier la prÃ©sence de NVIDIA via lspci
            try:
                output = subprocess.check_output(["lspci"], text=True)
                if "NVIDIA" in output:
                    gpu_info["nvidia_available"] = True
                    # Essayer d'extraire le nom du modÃ¨le
                    for line in output.split("\n"):
                        if "NVIDIA" in line:
                            gpu_info["model"] = line.split(":")[-1].strip()
                            break
                elif "AMD" in output or "Radeon" in output:
                    gpu_info["amd_available"] = True
                    # Essayer d'extraire le nom du modÃ¨le
                    for line in output.split("\n"):
                        if "AMD" in line or "Radeon" in line:
                            gpu_info["model"] = line.split(":")[-1].strip()
                            break
                elif "Intel" in output and "Graphics" in output:
                    gpu_info["intel_available"] = True
                    # Essayer d'extraire le nom du modÃ¨le
                    for line in output.split("\n"):
                        if "Intel" in line and "Graphics" in line:
                            gpu_info["model"] = line.split(":")[-1].strip()
                            break
            except (subprocess.SubprocessError, FileNotFoundError):
                logger.warning("lspci non disponible, impossible de dÃ©tecter le GPU")
    
    except Exception as e:
        logger.warning(f"Erreur lors de la dÃ©tection du GPU: {str(e)}")
    
    return gpu_info

def get_all_packages() -> List[str]:
    """
    DÃ©termine toutes les dÃ©pendances Ã  installer en fonction du matÃ©riel dÃ©tectÃ©.
    
    Returns:
        Liste des packages Ã  installer
    """
    packages = REQUIRED_PACKAGES.copy()
    
    # Ajouter les packages spÃ©cifiques Ã  la plateforme
    system = platform.system().lower()
    if system == "windows":
        packages.extend(PLATFORM_PACKAGES["win32"])
    elif system == "linux":
        packages.extend(PLATFORM_PACKAGES["linux"])
    elif system == "darwin":
        packages.extend(PLATFORM_PACKAGES["darwin"])
    
    # DÃ©tecter le GPU et ajouter les packages correspondants
    gpu_info = get_gpu_info()
    if gpu_info["nvidia_available"]:
        # NVIDIA est dÃ©tectÃ©, ajouter PyTorch avec CUDA
        logger.info(f"GPU NVIDIA dÃ©tectÃ©: {gpu_info['model']}")
        packages.extend(GPU_PACKAGES["torch"])
        packages.extend(GPU_PACKAGES["tensorflow"])
    elif gpu_info["amd_available"] or gpu_info["intel_available"] or gpu_info["apple_silicon"]:
        # AMD/Intel/Apple Silicon dÃ©tectÃ©, ajouter PyTorch sans CUDA
        logger.info(f"GPU dÃ©tectÃ©: {gpu_info['model']}")
        packages.extend(GPU_PACKAGES["torch"])
        packages.extend(GPU_PACKAGES["tensorflow"])
    
    # Dans tous les cas, ajouter les packages GPU communs
    packages.extend(GPU_PACKAGES["common"])
    
    return packages

def install_packages(packages: List[str]) -> bool:
    """
    Installe les packages spÃ©cifiÃ©s avec pip.
    
    Args:
        packages: Liste des packages Ã  installer
        
    Returns:
        True si l'installation a rÃ©ussi, False sinon
    """
    if not packages:
        logger.info("Aucun package Ã  installer")
        return True
    
    logger.info(f"Installation de {len(packages)} packages...")
    
    try:
        # Construire la commande pip avec tous les packages
        cmd = [sys.executable, "-m", "pip", "install", "--upgrade"]
        cmd.extend(packages)
        
        # ExÃ©cuter l'installation
        logger.info(f"ExÃ©cution de la commande: {' '.join(cmd)}")
        subprocess.check_call(cmd)
        
        logger.info("Installation des packages terminÃ©e avec succÃ¨s")
        return True
    
    except subprocess.CalledProcessError as e:
        logger.error(f"Erreur lors de l'installation des packages: {str(e)}")
        return False

def check_cuda_availability() -> Tuple[bool, str]:
    """
    VÃ©rifie si CUDA est disponible et retourne sa version.
    
    Returns:
        Tuple (disponibilitÃ©, version)
    """
    try:
        import torch
        
        cuda_available = torch.cuda.is_available()
        cuda_version = torch.version.cuda if cuda_available else "Non disponible"
        
        return cuda_available, cuda_version
    
    except ImportError:
        return False, "PyTorch non installÃ©"

def main():
    """Fonction principale d'installation des dÃ©pendances"""
    print_banner()
    
    print("\nğŸ“‹ VÃ©rification du systÃ¨me...")
    system = platform.system()
    release = platform.release()
    machine = platform.machine()
    
    print(f"SystÃ¨me dÃ©tectÃ©: {system} {release} ({machine})")
    
    # Obtenir la liste complÃ¨te des packages Ã  installer
    packages = get_all_packages()
    
    print(f"\nğŸ“¦ Packages Ã  installer ({len(packages)}):")
    for package in packages:
        print(f"  - {package}")
    
    # Demander confirmation Ã  l'utilisateur
    confirm = input("\nğŸ”„ Continuer avec l'installation? (o/n): ")
    if confirm.lower() != "o":
        print("âŒ Installation annulÃ©e")
        return 1
    
    # Installer les packages
    print("\nğŸ”„ Installation des packages...")
    success = install_packages(packages)
    
    if success:
        print("\nâœ… Installation terminÃ©e avec succÃ¨s!")
        
        # VÃ©rifier la disponibilitÃ© de CUDA si un GPU NVIDIA est dÃ©tectÃ©
        gpu_info = get_gpu_info()
        if gpu_info["nvidia_available"]:
            cuda_available, cuda_version = check_cuda_availability()
            
            if cuda_available:
                print(f"\nğŸ® CUDA est disponible (version {cuda_version})!")
                print("  â†’ Optimisations GPU activÃ©es pour les modÃ¨les d'IA.")
            else:
                print("\nâš ï¸ CUDA n'est pas disponible malgrÃ© la dÃ©tection d'un GPU NVIDIA.")
                print("  â†’ Les performances GPU pourraient Ãªtre limitÃ©es.")
        
        print("\nğŸ“ Pour utiliser l'optimiseur matÃ©riel, exÃ©cutez:")
        print("  python -m gbpbot.core.optimization.optimize_hardware")
        return 0
    else:
        print("\nâŒ L'installation a Ã©chouÃ©. Consultez les messages d'erreur ci-dessus.")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 